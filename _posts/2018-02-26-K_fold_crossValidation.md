---
layout:     post
title:      K-fold Cross Validation 
subtitle:   机器学习中的k折交叉验证
date:       2018-02-26
author:     Janeliao
header-img: img/in-posts/k_fold.jpg
catalog: 	true
tags:
    -  machine learning
---



在优达学城机器学习的入门课程P5项目进行过程中，对K折交叉验证的理解出了问题，导致项目多次不通过，在此将k折交叉验证进行解释，并加深印象。

**交叉验证的目的：**在实际训练中，模型通常对训练数据好，但是对训练数据之外的数据拟合程度差。用于评价模型的泛化能力，从而进行模型选择。如果数据量不大，随机性也不够好，比如分布有顺序性，那么分出来的验证集有可能只包含数据集中一种特点的数据，这时候在验证集上得到的分数可能是不准确的。有可能是模型拟合得比较好的数据，得到的成绩优于真实表现；有可能是模型拟合得比较差的数据，得到的成绩差于真实表现。如果使用交叉验证，那么就会取多次不同的验证集分数的平均值，多次取平均值能够减少对模型表现评分的误差，这样就可以更准确地找到最优参数。

k折交叉验证是指将数据集分成k个子集，选择其中一个子集为验证集，其余k-1个子集为训练集；重复验证k次，每次选择一个子集为验证集，并将k次的平均交叉验证评分作为结果。

在网格搜索的过程中使用交叉验证，可给出准确的评分，找到最优参数。